{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "python-simple-web-scrape.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "[View in Colaboratory](https://colab.research.google.com/github/pascalesdedy/python-simple-web-scrape/blob/master/python_simple_web_scrape.ipynb)"
      ]
    },
    {
      "metadata": {
        "id": "e-sUp5CzlE_b",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# **Learn Web Scrapping with Python**\n"
      ]
    },
    {
      "metadata": {
        "id": "9zlMrzHOmTPZ",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Simple python script for web scrapping\n"
      ]
    },
    {
      "metadata": {
        "id": "evIy8X3gxown",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Your first task will be to download web pages.\n",
        "\n",
        "The requests package comes to the rescue. It aims to be an easy-to-use tool for doing all things HTTP in Python, and it doesn’t dissappoint. In this tutorial, you will need only the requests.get() function, but you should definitely checkout the full documentation when you want to go further.\n",
        "\n",
        "First, here’s your function:"
      ]
    },
    {
      "metadata": {
        "id": "UQ9T_RS0mhsy",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from requests import get\n",
        "from requests.exceptions import RequestException\n",
        "from contextlib import closing\n",
        "from bs4 import BeautifulSoup\n",
        "\n",
        "def simple_get(url):\n",
        "    \"\"\"\n",
        "    Attempts to get the content at `url` by making an HTTP GET request.\n",
        "    If the content-type of response is some kind of HTML/XML, return the\n",
        "    text content, otherwise return None.\n",
        "    \"\"\"\n",
        "    try:\n",
        "        with closing(get(url, stream=True)) as resp:\n",
        "            if is_good_response(resp):\n",
        "                return resp.content\n",
        "            else:\n",
        "                return None\n",
        "\n",
        "    except RequestException as e:\n",
        "        log_error('Error during requests to {0} : {1}'.format(url, str(e)))\n",
        "        return None\n",
        "\n",
        "\n",
        "def is_good_response(resp):\n",
        "    \"\"\"\n",
        "    Returns True if the response seems to be HTML, False otherwise.\n",
        "    \"\"\"\n",
        "    content_type = resp.headers['Content-Type'].lower()\n",
        "    return (resp.status_code == 200 \n",
        "            and content_type is not None \n",
        "            and content_type.find('html') > -1)\n",
        "\n",
        "\n",
        "def log_error(e):\n",
        "    \"\"\"\n",
        "    It is always a good idea to log errors. \n",
        "    This function just prints them, but you can\n",
        "    make it do anything.\n",
        "    \"\"\"\n",
        "    print(e)\n",
        "    \n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "LnNtlSEvozWy",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "The simple_get() function accepts a single url argument. \n",
        "It then makes a GET request to that URL. If nothing goes wrong, you end up with the raw HTML content for the page you requested. \n",
        "If there were any problems with your request (like the URL is bad, or the remote server is down), then your function returns None.\n",
        "\n",
        "You may have noticed the use of the closing() function in your definition of simple_get(). The closing() function ensures that any network resources are freed when they go out of scope in that with block.\n",
        "Using closing() like that is good practice and helps to prevent fatal errors and network timeouts."
      ]
    },
    {
      "metadata": {
        "id": "NmTRwwNpniXK",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "4c32f6a2-49e8-4fdb-8492-264e83d27e11"
      },
      "cell_type": "code",
      "source": [
        "raw_html = simple_get('https://realpython.com/blog/')\n",
        "len(raw_html)    "
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "254791"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "metadata": {
        "id": "WFOs4gnln8zM",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### **Using Beautiful soup**"
      ]
    },
    {
      "metadata": {
        "id": "gEo2jYSGxK6m",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Fetch Mathematician name"
      ]
    },
    {
      "metadata": {
        "id": "IEJylqgFoEWX",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "raw_html = simple_get('http://www.fabpedigree.com/james/mathmen.htm')\n",
        "html = BeautifulSoup(raw_html, 'html.parser')\n",
        "for i, li in enumerate(html.select('li')):\n",
        "      print(i, li.text)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "TQOHgcz4qcna",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Fetch popular News\n"
      ]
    },
    {
      "metadata": {
        "id": "WA2KmveUpcHp",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "raw_html = simple_get('http://jogja.tribunnews.com/populer')\n",
        "html = BeautifulSoup(raw_html, 'html.parser')\n",
        "for i, a in enumerate(html.select('a')):\n",
        "     print(i, a.text)\n",
        "\n",
        "    \n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "06it0wwIpb2-",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        ""
      ]
    },
    {
      "metadata": {
        "id": "_nAl4zlWqRkv",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}